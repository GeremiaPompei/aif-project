algorithm_name,total_steps,steps_first_door,steps_first_key,steps_first_corridor,total_run,total_wins,total_lost,execution_time,memory_usage,
ReinforcementLearning(DQN(from-scratch)),1000.0,0.0,337.0,340.0,1,0,1,50.036137104034424,335855616.0,
ReinforcementLearning(DQN(DQN.torch)),1000.0,0.0,215.0,0.0,1,0,1,51.26249408721924,353681408.0,
RuleBased,999.0,92.0,3.0,94.0,1,0,1,0.12195420265197754,360873984.0,
PathFinding(BreadthFirst),165.0,7.0,4.0,31.0,1,1,0,1.773622989654541,363200512.0,
PathFinding(Greedy(heuristic: manhattan)),113.0,0.0,6.0,13.0,1,1,0,1.0552198886871338,365527040.0,
PathFinding(Greedy(heuristic: euclidean)),100.0,13.0,3.0,14.0,1,1,0,0.9551630020141602,367853568.0,
PathFinding(Greedy(heuristic: not_walkable_steps_in_matrix)),252.0,0.0,2.0,7.0,1,1,0,2.5001111030578613,370049024.0,
PathFinding(UniformCost),116.0,0.0,7.0,28.0,1,1,0,1.066709041595459,372391936.0,
PathFinding(AStar(heuristic: manhattan)),204.0,15.0,3.0,32.0,1,1,0,2.0019891262054443,374734848.0,
PathFinding(AStar(heuristic: euclidean)),487.0,229.0,4.0,14.0,1,1,0,4.704936981201172,377061376.0,
PathFinding(AStar(heuristic: not_walkable_steps_in_matrix)),1000.0,16.0,9.0,23.0,1,0,1,7.5872039794921875,363102208.0,
